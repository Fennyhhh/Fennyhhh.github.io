---
layout:     post
title:      "论文阅读——EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
subtitle:   " \"图像分类\""
date:       2019-11-15 19:32:00
author:     "Fenny"
header-img: "img/post-bg-2015.jpg"
tags:
    - 论文阅读
---

# 文章标题
EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
# 文章思路
对目前分类网络的优化提出更加泛化的思想，这篇文章认为目前常用的加宽网络、加深网络和增加分辨率这3种常用的提升网络指标的方式之间不应该是相互独立的。因此提出了compound model scaling算法，通过综合优化网络宽度、网络深度和分辨率达到指标提升的目的，能够达到准确率指标和现有分类网络相似的情况下，大大减少模型参数量和计算量。

# 网络结构
！[efficientnet](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/efficientnet.jpg)
如图所示，常用的三种网络调节方式：增大感受野w，增大网络深度d，增大分辨率大小r，其中，(a)为基线网络，也可以理解为小网络；(b)为增大感受野的方式扩展网络；(c)为增大网络深度d的方式扩展网络；(d)为增大分辨率r的方式扩展网络；(e)为本文所提出的混合参数扩展方式。
# 公式
在公式1中，N表示分类网络，X表示输入，Fi表示基础网络层，i表示stage，Li表示Fi结构在第i个stage中的重复数量。公式1这样的定义方式对应的最直观例子就是ResNet系列网络，我们知道ResNet系列网络有多个stage，每个stage包含不同数量的block结构。
* ！[efficientnet_eq1](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/efficientnet_eq1.jpg)

那么model scaling的目标就是在模型参数和计算量满足限制条件的情况下最大化网络的准确率，也就是公式2所表达的内容，待优化的参数就是网络深度（d）、网络宽度（w）和分辨率（r）。
* ！[efficientnet_eq2](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/efficientnet_eq2.jpg)
论文中基线模型使用的是 mobile inverted bottleneck convolution（MBConv），类似于 MobileNetV2 和 MnasNet，但是由于 FLOP 预算增加，该模型较大。于是，研究人员缩放该基线模型，得到了EfficientNets模型。对比EfficientNets和已有的CNN模型，EfficientNet 模型要比已有 CNN 模型准确率更高、效率更高，其参数量和 FLOPS 都下降了一个数量级，EfficientNet-B7 在 ImageNet 上获得了当前最优的 84.4% top-1 / 97.1% top-5 准确率，而且CPU 推断速度是 Gpipe 的 6.1 倍，但是模型大小方面，EfficientNet-B7却比其他模型要小得多，同时，还对比了ResNet-50，准确率也是胜出一筹(ResNet-50 76.3%，EfficientNet-B4 82.6%)。

# 总结与思考
看了文章的实验结果发现，在r和w大小不变的情况下，随着d的增大，准确率没有太大的差异，（正好是现在我碰到的的问题）；在d和w不变的情况下，随着r的增大，准确率有较大提升；r和d不变的情况下，随着w的增大，准确率先有较大提升，然后趋于平缓，往后在无太大提升。根据这篇文章，可以进一步思考针对r和w如何改进。