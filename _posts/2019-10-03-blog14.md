---
layout:     post
title:      "论文阅读——Object Region Mining with AE:A Simple Classification to Semantic Segmentation Approach"
subtitle:   " \"弱监督语义分割\""
date:       2019-10-03 15:56:00
author:     "Fenny"
header-img: "img/post-bg-2015.jpg"
tags:
    - 论文阅读
---
# 文章名称
Object Region Mining with Adversarial Erasing: A Simple Classification toSemantic Segmentation Approach
# 文章来源
cvpr,2017
# 文章动机
CAM,类别激活图是利用训练好的分类网络，通过top-down方式估计出每个类别在图像上的相应区域，从而可以定位出与类别相关区域。<br>
分类网络通常仅依赖于物体的某些判别区域。比如，狗的头部通常具有较强的判别力，可以使网络识别出该图片中包含狗，从而忽略狗的其他区域。<br>
但对于弱监督学习的语义分割任务而言，我们需要比较稠密和完整的localization map去训练更好的模型。而仅仅依赖于分类网络直接生成的localization map很难训练出有效模型。<br>

# 研究方法
![ae1](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/ae1.jpg)<br>
看上面这张图，将第一张图片以及它对应的标签“person”输入到网络中进行训练。继而，网络会尝试从图中发现一些证据来证明图中包含了“person”。一般来讲，人的head是最具判别力的部位，可以使此图被正确地判别为“person”。若将head从图片中移除（如第二张图中的橙色区域），网络会继续寻找其它证据来使得图像可以被正确分类，进而找到人的body区域。重复此操作，人的foot区域也可以被发现。由于训练本身是为了从图片中发现对应标签的证据而擦除操作则是为了掩盖证据，因此我们称这种训练-擦除-再训练-再擦除的方式为对抗擦除（adversarial erasing）<br>
![ae2](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/ae2.jpg)<br>
训练过程也是如此，我们先将上图包含狗的图片输入分类网络，可以通过训练得到对于狗而言最具判别力的区域，如狗的头部。接下来我们将狗的头部从图片中擦除掉（擦除指把这部分的像素值在网络中设置为0），并将擦除后的图片输入分类网络进行再训练。网络会寻找其它证据来使得图像可以被正确分类，进而找到狗的胸部。重复此操作狗的脚部区域也可以被发现。最后可以通过融合擦除掉的区域获取物体的整个区域。上图给出了不同擦除阶段所获取的物体的不同部位，以及最后通过融合得到的整个物体的区域。<br>
## 网络
1. Adversarial Erasing<br>
首先训练一个分类网络VGG-16，并利用CAM方法获取localization map。进而通过一个阈值获取判别区域并将其对应的像素从训练图片中擦除后重新输入网络进行训练（每次训练持续5个epochs）。将最后两个全连接层替换为卷积层，CAM被用来定位标签相关区域。在生成的location map（H）中，属于前20%最大值的像素点被擦除。我们具体的擦除方式是将对应的像素点的值设置为所有训练集图片的像素的平均值。<br>
我们将挖掘出的区域从原始图片中擦除，并将擦除后的图像训练另一个分类网络来定位其它的物体区域。我们重复此过程，直到网络在被擦除的训练图像上不能很好地收敛。最后将被擦除的区域合并起来作为挖掘出的物体区域.<br>
![ae3](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/ae3.jpg)<br>
2. online Prohibitive Segmentation Learning (PSL)<br>
由于生成的segmentation mask包含了一些噪声区域和未被标注的区域，为了更加有效地训练，我们提出了一种PSL（prohibitive segmentation learning）方法训练语义分割网络。<br>
PSL引入了一个多标签分类的分支用于在线预测图像包含各个类别的概率值，这些概率被用来调整语义分割分支中每个像素属于各个类别的概率，并在线生成额外的segmentation mask作为监督信息。由于图像级的多标签分类往往具有较高的准确性，PSL方法可以利用分类信息来抑制分割图中的true negative区域。随着训练的进行，网络的语义分割能力也会越来越强，继而在线生成的segmentation mask的质量也会提升，从而提供更加准确的监督信息。<br>
PSL+是指做了一步迭代操作的结果。类似STC的做法，PSL+通过训练好的分割网络首先对训练样本做预测，进而通过CRF和图像标签修正了分割结果，最后利用网络预测的segmentation mask作为监督信息训练分割网络。总体来讲，PSL性能提升主要来源于两方面：训练过程中可以online地生成更准确的监督信息；classification分支提供的Image-level的分类结果可以作为一种后处理机制去修正分类结果。<br>
3. 测试<br>
在测试过程中，对于那些分类信任度低的分类，我们采取了更严格的策略。特别地，我们将那些小于p的分类置信区间设为0，并保持其他分类置信区间不变，应用它们对预测的分割分数映射进行加权，得到最终的分割结果。在这种操作下，可以通过将一个小的分类得分相乘来抑制来自负分数映射的较大响应值。同时，还可以增强占主导地位的类别(即占图像较大面积的对应对象)的得分图.<br>
4. 何时停止擦除？<br>
对于AE，何时停止擦除操作是一个关键的问题。这里我们通过观察分类网络上loss值的变化做决策。最下面的红色线是直接用原图做训练得到的loss曲线，可以看出loss可以降到非常低。在不断的擦除过程中，loss值也在逐渐上升，说明网络已经逐渐失去了判别训练样本类别的能力，如最上一条曲线所示，loss值收敛在一个较大的值。实施第四次擦除后，网络训练收敛后的loss值会有较大提升。主要原因在于大部分图片中的物体的区域已经被擦除，这种情况下大量的背景区域也有可能被引入。因此我们只合并了前三次擦除的区域作为图片中的物体区域第四步擦除降低了mIoU，因此我们只融合了前三次擦除的结果作为物体的区域。

# 实验结果
前面讲到的STC的性能为51.2，AE-PSL方法达到了55.7。

# 总结与思考
这篇文章与STC那一篇出自同一个作者，思路都是要在弱监督语义分割的过程中引入位置先验信息，以提升分割的效果。但是这两篇文章引入位置先验信息的方法是不同的，前一个是利用了显著性图，这种方法是自底向上的提取特征，后一个是自顶向下的，让网络自己去寻找，提取到的是高级的语义信息。对抗擦除的想法也十分值得借鉴。








