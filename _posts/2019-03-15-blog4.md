---
layout:     post
title:      "论文阅读——DropBand & When Deep Learning Meets Metric Learning"
subtitle:   " \"图像分类\遥感场景分类\度量学习\""
date:       2019-03-15 10:42:00
author:     "Fenny"
header-img: "img/post-bg-2015.jpg"
tags:
    - 论文阅读
---

# 文章标题
两篇关于遥感场景分类的文章：
1. DropBand: A Simple and Effective Method for  Promoting the Scene Classifification Accuracy of  Convolutional Neural Networks for VHR Remote Sensing Imagery
2. When Deep Learning Meets Metric Learning:  Remote Sensing Image Scene Classifification  via Learning Discriminative CNNs

# 第一篇DropBand
## 文章来源
IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
## 文章思路
Dropout是一种常用的防止CNN过拟合的方法，但是Dropout是对图像的平面进行处理，而不是针对输入通道。文章提出一种方法DropBand，通过在原始影像中去除某些光谱波段，可以生成更多的训练样本。将所有具有相同光谱波段的样本集合在一起，训练出一个基本的CNN。测试样本的最终预测由所有基本CNNs输出的组合表示。
## 网络结构
！[dropband](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/dropband.jpg)
如图所示：DropBand方法通过从每个图像中选择输入波段的子集来增强训练数据。假设VHR遥感图像中出现四个波段：红色（R），绿色（G），蓝色（B）和近红外（NIR）。这个图像显示了从四个通道中选择三个通道的过程，也就是从原始图像中丢弃一个通道，这样看drop率是0.75。
在DropBand中，原始图像和增强图像都用于训练分类器并对测试图像进行预测。如图所示，DropBand中的网络架构是多个基本CNN的组合。基本CNN的数量取决于用于从原始图像中丢弃通道的方法。最后将具有相同光谱带组的所有图像收集在一起以训练基础CNN。测试图像的最终预测表示所有基本CNN的输出的组合。
文章将原始的CNN、采用了Dropout集成的CNN和采用了Dropband的CNN做对比，发现丢弃一个通道再集成的做法要优于Dropout。丢弃更多的通道，网络的整体性能会变差，并且随着基础CNN的增加，计算成本也会大大增加，这样是非常耗时的。
## 总结与思考
这篇文章是对Dropout的另一个思路，通过丢弃波段数来增强网络性能，但是这个dropband针对的是输入影像的波段。但是这篇文章最后是对dropband的结果做了集成，单个分类器的性能可能不一定好。首先看到Dropband这个想法，第一反应是应该适合高光谱影像的处理，但这只能适用于单个分类器，高光谱影像的波段众多，每次丢弃一个或者几个再进行集成，这样得到的基础CNN会很多，非常消耗计算资源。

# 第二篇When Deep Learning Meets Metric Learning
## 文章来源
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
## 文章思路
类内多样性和类间相似性的问题仍然是遥感图像场景分类的两大挑战。针对这些问题，这篇文章提出了一种简单有效的学习Discriminative CNNs (D-CNNs)的方法，优化一个新的判别目标函数，添加了一个度量学习正则化项，使D-CNN模型具有更强的识别力，使得在新的D-CNN特征空间中，来自同一个场景类的图像相互映射得更紧密，不同类的图像映射得更远，以提高遥感图像场景分类的性能。度量学习的重点是在保持所需距离结构的数据对(例如，图像)之间找到合适的相似性度量。 这篇文章采用了对比嵌入的方法对D-CNN模型进行训练，度量学习正则化不仅用于学习判别特征表示，而且还探索了同时训练有效分类器的方法。
## 网络结构
！[d-cnn](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/d-cnn.jpg)
上图展示了文中方法的核心思想。该方法的目标是学习用于场景分类的D-CNNs，以解决类内多样性和类间相似性的挑战。这样就可以提取出更强大的CNN特征，进一步提高目前性能最先进的深度学习方法。为此，除了最小化交叉熵损失(即传统CNN模型最后FC层的softmax分类误差)，该文还在CNN的特征上增加了一个度量学习正则化项，以增强D-CNN模型的区分能力。因此，在图底部所示的D-CNN feature spaces中，来自同一个场景类的图像尽可能的近，不同类的图像尽可能的远。文章根据图像场景类构造了相似对和不相似对，如果两个图像共享相同的场景标签，则认为它们是相似的一对;否则，它们将被视为不同的一对。
度量学习的正则化项的损失函数如下:
！[d-cnnloss](/d-cnnloss.jpg)
h(x)=max(0,x)时是hinge损失函数。τ的值计算如下：通过假设相似对和不相似对的距离服从正态分布，我们首先使用正常cnn特征绘制相似对和不相对的概率密度分布曲线，然后获得这些对的连接点。 这里，两条曲线交点的x轴值是待计算的τ值。
## 总结与思考
这篇文章的D-CNN模型是通过优化新的判断目标函数进行训练，该目标函数除了最小化分类错误（交叉熵）之外，还对CNN特征施加度量学习正则化项（样本对的距离度量函数）。这篇文章的关注点在于类内距离和类间距离，分类的任务就是要让类内距离尽可能小，而类间距离尽可能大。通过构造相似样本对和不相似样本对，用距离度量的损失函数来衡量类间和类内距离是一种可行的方法。文中为了保持样本平衡，相似样本对和不相似样本对的数量是相等的，但在实际情况里，各个类别之间的样本数量往往是不平衡的，要达到相等的样本对数量，还得考虑数据增强的方法。

