---
layout:     post
title:      "从R-CNN到Mask—RCNN"
subtitle:   " \"目标检测，实例分割\""
date:       2019-01-26 17:56:00
author:     "Fenny"
header-img: "img/post-bg-2015.jpg"
tags:
    - 研究回顾
---
# R-CNN
## R-CNN的思路
![rcnn](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/rcnn.jpg)<br>
1. 得到若干候选区域（selective search）；
2. 对每个候选区域分别用CNN分类；
3. 对每个候选区域分别进行边框预测。

## R-CNN的问题
太慢！
主要有三方面原因：
1. 候选区域的生成是一个耗时的过程；
2. 对候选区域特征提取需要在单张图像上使用AlexNet 2000多次； 
3. 特征提取、图像分类、边框回归是三个独立的步骤，要分别进行训练，测试过程中的效率也较低。

# Fast R-CNN
## 思路
提出了一个ROI Pooling的方法，先对输入图像使用一次CNN前向计算，得到整个图像的特征图，再在这个特征图中分别取提取各个候选区域的特征。
![fastrcnn](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/fastrcnn.jpg)<br>
Fast R-CNN的第二点创意是把之前独立的三个步骤（特征提取、分类和回归）放到一个统一的网络结构中。
该网络结构同时预测一个候选区域的物体类别和该物体的边界框，使用两个全连接的输出层分别进行类别预测和边框预测，将这两个任务进行同时训练。
![fastrcnn1](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/fastrcnn1.jpg)<br>
## R-CNN vs. Fast R-CNN
![rcnn1](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/rcnn1.jpg)<br>
R-CNN结构图<br>
![fastrcnn2](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/fastrcnn2.jpg)<br>
 Fast R-CNN结构图<br>

# Faster R-CNN
Faster R-CNN提出使用CNN来得到候选区域。有两个卷积神经网络，一个是区域生成网络，得到图像中的各个候选区域，另一个是候选区域的分类和边框回归网络。<br>
候选区域生成网络（Region Proposal Network, RPN）如下，先通过对输入图像的数层卷积得到一个特征图像，然后在特征图像上生成候选区域。它使用一个n\times n（n=3）的滑动窗口，将局部的特征图像转换成一个低维特征, 预测k个的区域（cls层，2k个输出）是否为候选区域和对应的k个边框（reg层，4k个输出）。这里的k个区域被称为锚（anchor）， 对应着与滑动窗口具有相同的中心的不同大小和不同长宽比的矩形框。假设卷积后的特征图像大小为W\times H,那么一共有WHk个锚。这种特征提取和候选区域生成的方法具有位移不变性。<br>
![rpn](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/rpn.jpg)<br>

# Mask R-CNN
Mask R-CNN是在 Faster R-CNN 上的扩展——在其已有的用于边界框识别分支上添加了一个并行的用于预测目标掩码的分支。
## 优势
1. 在边框识别的基础上添加分支网络，用于 语义Mask 识别；
2. 训练简单，相对于 Faster 仅增加一个小的 Overhead，可以跑到 5FPS；
3. 可以方便的扩展到其他任务，比如人的姿态估计 等；
4. 在每个任务上，效果优于目前所有的 single-model entries。
![maskrcnn1](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/maskrcnn1.jpg)<br>
## 技术要点
1. 强化的基础网络<br>
通过 ResNeXt-101+FPN 用作特征提取网络，达到 state-of-the-art 的效果。
2. ROIAlign<br>
采用 ROIAlign 替代 RoiPooling（改进池化操作）。引入了一个插值过程，先通过双线性插值到14*14，再 pooling到7*7，很大程度上解决了仅通过 Pooling 直接采样带来的 Misalignment 对齐问题。 
3. Loss Function<br>
每个 ROIAlign 对应 K * m^2 维度的输出。K 对应类别个数，即输出 K 个mask，m对应 池化分辨率（7*7）。Loss 函数定义：
Lmask(Cls_k) = Sigmoid (Cls_k)，<br>    
平均二值交叉熵 （average binary cross-entropy Loss，通过逐像素的 Sigmoid 计算得到。
![maskrcnn](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/maskrcnn.jpg)<br>

