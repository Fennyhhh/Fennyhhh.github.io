---
layout:     post
title:      "论文阅读——Squeeze-and-Excitation Networks"
subtitle:   " \"图像分类\""
date:       2018-10-20 14:56:00
author:     "Fenny"
header-img: "img/post-bg-2015.jpg"
tags:
    - 论文阅读
---
# 文章标题
Squeeze-and-Excitation Networks

# 文章来源
ieee2017

# 动机
卷积核作为卷积神经网络的核心，通常被看做是在局部感受野上，将空间上（spatial）的信息进行聚合的信息聚合体。但目前的卷积是在 2D 空间中做卷积，其本质上来说只建模了图像的空间信息，并没有建模通道之间的信息。于是，作者就尝试对 Channel 之间的信息进行显式建模。

# 网络结构
！[senet](../img/senet.jpg)
左边为 C'×H'×W' 的特征图，经过一系列卷积，pooling 操作 Ftr 之后，得到 C×H×W 大小的特征图。接下来进行一个 Sequeeze and Excitation block。
## Sequeeze
对 C×H×W 进行 global average pooling，得到 1×1×C 大小的特征图，这个特征图可以理解顺着空间维度来进行特征压缩，将每个二维的特征通道变成一个实数，在某种程度上具有全局的感受野，并且输出的维度和输入的特征通道数相匹配。它表征着在特征通道上响应的全局分布，而且使得靠近输入的层也可以获得全局的感受野，这一点在很多任务中都是非常有用的
## Excitation
使用一个全连接神经网络，对 Sequeeze 之后的结果做一个非线性变换。它是一个类似于循环神经网络中门的机制。通过参数 w 来为每个特征通道生成权重，其中参数 w 被学习用来显式地建模特征通道间的相关性。
## 特征重标定
Excitation 的输出的权重看做是进过特征选择后的每个特征通道的重要性，然后通过乘法逐通道加权到先前的特征上，完成在通道维度上的对原始特征的重标定.
！[senet_insert](../img/senet_insert.jpg))

# 总结与思考
这个结构可以作为任意网络的子模块添加进去以提升精度，而且引入的计算量非常小。作者在聚合通道之间的信息时，并未引入一个新的空间维度来进行特征通道间的融合，而是采用了一种全新的特征重标定策略。具体来说，就是通过学习的方式来自动获取到每个特征通道的重要程度，然后依照这个重要程度去提升有用的特征并抑制对当前任务用处不大的特征。