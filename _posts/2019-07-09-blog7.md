---
layout:     post
title:      "遥感场景分类比赛策略"
subtitle:   " \"场景分类，比赛，遥感\""
date:       2020-02-18 22:56:00
author:     "Fenny"
header-img: "img/post-bg-2015.jpg"
tags:
    - 场景分类\比赛\遥感
---

暑假参加了一个遥感大型场景分类比赛，总结了一些可用的比赛经验策略。
# 一、数据集分析
1. 数据量庞大，且训练集图像尺寸不一
训练集数据将近18万张，训练集图片尺寸以512*512和256*256这两种尺寸居多，此外还有256*257等其他尺寸。但测试数据均为512*512尺寸。
2. 样本不均衡问题
每个类别样本数量不均衡，各种类别的数据从最多11801张（梯田）到最少1109张（路边停车区）图像。
3. 类别混淆问题
数据集中一共有45个类别，有许多类别之间存在特征相似，难以区分的情况
4. 相同类别特征多样、尺度不一问题

# 二、baseline模型训练与选择
Baseline模型的训练是在数据增强之前需要完成的工作，一个好的模型可以带来6-10%的精度提升，因此在这个环节中，需要搜集并训练泛化能力强，鲁棒性强，训练时长合理的模型，在后面可以遴选出性能好的模型进行集成学习。
选择对比基准模型，可检测模型在 ImageNet 数据集上的性能，查看 Keras 中每个模型（https://keras.io/applications/）的参数个数。
1. VGG16
训练完成，验证集和测试集的精度79%+
特点：训练时间短，模型结构简单，但网络分类性能一般；
2. Inception-ResNet-v2
训练完成，验证集和测试集的精度87.5%+
特点：网络复杂度高，训练时间是VGG16的3倍，但精度提升了8%左右；
3. ResNet34
4. ResNet50
5. SE-ResNet-50 
6. SE-ResNet-101
Baseline训练结束后，需要对验证集数据做混淆矩阵分析，后续才能对数据进行更有针对性的处理。
# 三、数据处理
## 数据增强
1. 简单数据增强，通过旋转/镜像/随机裁剪/添加噪声等实现
已完成，但并不是针对整个数据集的数据增强，而是只针对数据量少的类别进行增强。将低于2000张的类别图片扩充至原有数量的4倍，2000-3000的类别扩充至原有数量的3倍，3000-4000的类别扩充至原有数量的2倍。目前数据量已增加至30w+
2. 使用imgaug这个图片数据增强库来进行数据增强
Github位置为：https://github.com/aleju/imgaug。
（这个图像增强库的算法较简单的数据增强更为丰富全面)
3. 使用GAN进行数据增强
Github位置为：https://github.com/NVIDIA/pix2pixHD
使用GAN进行数据增强可增强样本的多样性，前两种方法的数据增强都无法达到这种效果。但用GAN 生成的图片质量无法保证。
## 数据平衡
###  采样平衡
1. 训练时的Label Shuffling平衡策略
* 首先对原始的图像列表，按照标签顺序进行排序；
* 然后计算每个类别的样本数量，并得到样本最多的那个类别的样本数。
* 根据这个最多的样本数，对每类随机都产生一个随机排列的列表；
* 然后用每个类别的列表中的数对各自类别的样本数求余，得到一个索引值，从该类的图像中提取图像，生成该类的图像随机列表；
* 然后把所有类别的随机列表连在一起，做个Random Shuffling，得到最后的图像列表，用这个列表进行训练。
每个列表，到达最后一张图像的时候，然后再重新做一遍这些步骤，得到一个新的列表，接着训练。Label Shuffling方法的优点在于，只需要原始图像列表，所有操作都是在内存中在线完成，非常易于实现。
2. Label Smoothing策略
Label Smoothing，是Google的CVPR论文中提出来的方法。根据混淆矩阵（Confusion Matrix）的分析，发现存在很多跨标签的相似性问题，这可能是由于标签模糊性带来的。所以，对混淆矩阵进行排序，得到跟每个标签最相近的4个标签，用它们来定义标签的先验分布，将传统的 one-hot标签，变成一个平滑过的soft标签。通过这种改进，我们发现可以从某种程度上降低过拟合问题。(精度提升在0.2~0.3左右)
### 训练平衡
模型在样本数量较少的类别上的性能并不太好。所以，将一个具有少数样本的类误分类为一个样本数量较多的类的成本通常要比将数量较多的类误分类高得多。
由此，可以使用两种方法来平衡数据：
1. 针对不平衡学习的自适应样本合成方法（ADASYN）
ADASYN 为样本较少的类生成合成的数据，这种方法会生成更多较难学习的数据集样本。ADASYN 的核心思想是，根据学习的困难程度，对样本数少的类别实例使用加权分布。ADASYN 通过两种方法提高了对数据分布的学习效果：
* 减少类别的不平衡所带来的偏差。
* 自适应地将分类的决策边界转换为更困难的样本。(https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4633969&tag=1)
2. 少数类过采样技术（SMOTE）：
SMOTE 包括对少数类的过采样和多数类的欠采样，从而得到最佳抽样结果。我们对少数（异常）类进行过采样并对多数（正常）类进行欠采样的做法可以得到比仅仅对多数类进行欠采样更好的分类性能（在 ROC 空间中）
(https://jair.org/index.php/jair/article/view/10302)


# 四、训练方法
## 1.Finetune
可参阅Andrej Karpathy 的博客（https://medium.com/@karpathy）
从头开始训练一个卷积神经网络（CNN）的效率相当低下，我们将利用在包含 1000 类图像的 ImageNet 上预训练好的卷积神经网络（CNN）的权重，然后通过将某些层保持为「冻结」状态，再将一些层解冻并进行训练，从而进行调优。（之前普遍的Finetune做法通常没有选择冻结，将现有数据集和原来的模型绑太紧，对训练有一定影响）
## 2.学习率调优
在网络运行时，学习率如果未做修改，通常为一个默认的数值（通常为0.01），在训练的每一个epoch都将使用这个学习率进行网络的学习和收敛。但在网络训练的后几个批次，训练已趋向饱和，我们需要一个更小的学习率，以找到网络最优解。
1. 解冻一些模型底部的层，并且令其学习率呈指数形式递减。
（学习率调整的相关博客：https://blog.csdn.net/zzc15806/article/details/79711114）
2. 周期性学习率，它实际上让我们不必再通过大量实验找到全局学习率的最优值和最佳学习计划。这种方法并不是单调地减小学习率，而是让学习率周期性地在合理的边界值之间变化。利用周期性学习率代替固定的学习率进行训练，能够有效地在不用进行调优的情况下提升分类准确率，需要的迭代次数往往也更少。
(详情请参阅论文:https://arxiv.org/pdf/1506.01186.pdf)
3. 带热重启的学习率（learning rate with warm restarts）技术:
(详情请参阅论文:https://arxiv.org/pdf/1608.03983.pdf)
## 3.改进损失函数
（论文名称：《Deep Discriminative Representation Learning with Attention Map for Scene Classification》，cscv2019）
主要贡献：
1. 提出了一种新颖的DDRL-AM学习方案，以解决遥感图像场景分类任务中的类内不一致和类间隐蔽问题，实现学习特征以确保类内紧凑性和类间可辨性。
2. 从预训练模型中生成与原始图像相关的注意图作为分类任务的先验，并使注意图首次成为端到端训练的显式输入组件，旨在强制网络 将注意力集中在最具辨别力的部分上。
3. 设计了一种新颖的特征融合模式，通过结合注意力图和原始像素空间有效地提取可辨识的特征。
4. 为了增强判别力，引入了一种新的损失函数，它同时学习每个类的深层特征的中心，并增加不同类的决策边界。

## 4.课程学习
（详细资料参阅：https://blog.csdn.net/XWUkefr2tnh4/article/details/78899543）
课程学习的基本思想是，将一个复杂的任务分成一系列子任务，把任务按简单到难的程度进行排序，在学习过程中让模型由易到难地学习。在大规模数据里，我们可以把整个数据集分成一系列子集， 将子集按简单干净数据到复杂有噪数据进行排序，然后在模型训练过程中，让网络从简单干净的数据集开始学习，通过增加数据集的难度逐渐提高模型的能力。这个机理和人的学习机理是非常相似的，人类接受的教育也是经过由易到难高度组织编排的。
课程学习首先将学习任务分成一系列子任务，然后根据难度对子任务进行排序，再设置一个任务转换的阈值（从一个任务跳转到另一个任务的条件）。从机器学习的角度来看，课程学习就是在各个子任务之间寻找一个最优路径使得整个模型能够收敛得更快且具备更好的泛化能力。它的整体思路非常简单：学习完一个简单任务之后再开始学习一个更难的任务。
## 5.多尺度训练
由于训练集尺度不一的问题，在训练出最优模型后，我们需要多尺度输入训练网络，尺度的选择还有待商榷。这一步有利于最后的集成学习。

# 测试与集成
1. 测试集的数据增强
在训练的时候，我们通常都需要做数据增强，在测试的时候，我们通常很少去做数据增强。当我们训练好某个模型后，对于某张测试图片，我们可以使用类似数据扩增的技巧生成与该张图片相类似的多张图片，并把这些图片送进我们训练好的网络中去预测，我们取那些投票数最高的类别为最终的结果。
如果在训练的最后几个epoch，移除数据增强，然后跟传统一样测试，可以提升一点性能。同样，如果训练的时候一直使用尺度和长宽比增强数据增强，在测试的时候也同样做这个变化，随机取32个crop来测试，也可以在最后的模型上提升一点性能。还有一条，就是多尺度的训练，多尺度的测试。另外，值得指出的是，使用训练过程的中间结果，加入做测试，可以一定程度上降低过拟合。
2. 集成学习
集成算法是一种优化手段或者策略，它通常是结合多个简单的弱机器学习算法，去做更可靠的决策。在比赛后期，我们可以将之前训练的几个性能较好的模型进行集成，可以提升模型效果。
框架主要三种：
* Bagging
* Boosting
* Stacking
