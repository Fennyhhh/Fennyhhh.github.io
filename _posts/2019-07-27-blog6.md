---
layout:     post
title:      "论文阅读——A novel Framework for remote  sensing image scene classification & Remote sensing scene classification based on rotation-invariant feature learning and joint decision making "
subtitle:   " \"图像分类,特征不变性,遥感\""
date:       2019-07-27 13:42:00
author:     "Fenny"
header-img: "img/post-bg-2015.jpg"
tags:
    - 论文阅读
---

# 文章标题
1. A novel Framework for remote  sensing image scene classification  
2. Remote sensing scene classification based on rotation-invariant feature learning and joint decision making
# 第一篇：A novel Framework for remote  sensing image scene classification  
## 文章来源
Remote Sensing and Spatial Information Sciences,2018
## 文章思路
该文章结合了卷积神经网络和XGBoost，它利用CNN作为特征提取器，XGBoost作为分类器。然后，在两个不同的HRRS图像数据集上（UC Merced数据集和NWPU-RESISC45数据集）表现良好。
## 网络结构：
![xg](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/xg.jpg)
网络结构分为：
1. 特征提取和选择，采用ImageNet上预训练的VGG-16模型
2. 分类器设计，XGBoost是一种集合方法，通过弱分类器的迭代计算提高分类的准确性。 第一阶段获得的特征被输入XGBoost分类器，此阶段输出图像的场景类别。
## 总结与思考
这个结构是比较惯用的深度卷积神经网络集成提升分类性能的典型结构。这篇文章没有做特别的创新，但和上一篇文章的相似之处都在于，强调了分类器的重要性，选择一个好的分类器代替卷积神经网络中原有的分类函数，在某些任务中可以达到更好的效果。


# 第二篇：Remote sensing scene classification based on rotation-invariant feature learning and joint decision making
## 文章来源
EURASIP Journal on Image and Video Processing, 2019, 2019(1).
## 文章思路
遥感数据集包括小规模的场景类，缺乏丰富的标签信息等，深度学习方法学习强大的特征表示是非常具有挑战性的。为克服这一问题，文章提出了一种基于孪生卷积神经网络的旋转不变特征学习和联合决策方法。首先，提出了一种新的数据增强策略，特别是针对孪生模型学习旋转不变特征。其次，引入了联合决策机制，通过识别和验证模型实现，以更好地提高分类性能。该方法不仅可以抑制由于缺乏丰富的标签样本引起的问题，而且可以提高卷积神经网络的鲁棒性。
## 网络结构
![identification.jpg](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/identification.jpg)
该网络由两个ImageNet 预先训练的CNN模型（AlexNet，VGG16 和ResNet50），这两个CNN模型结构相同，参数共享，以及三个额外的卷积层和一个方形层组成。CNN模型采用了一个核心层替换了原有的最终全连接层。
网络将一对图像作为输入。 输入对可以分为正面（来自同一场景类）和负面（来自不同类）。 给定一对图像，网络同时预先确定其标签和相似性， nonparametric square layer用于输入对的提取特征的相似性估计。原始图像被发送到一个CNN通道，而正图像（来自相同场景类别）或负图像（来自不同场景类别）被同时发送到其他CNN通道，然后利用两个参数共享的CNN来处理输入图像并提取它们的特征。识别模型使用CNN来提取特征，然后根据提取的特征预测图像的标签； 验证模型接受由两个CNN产生的两个特征向量作为输入，并利用方形层计算两个图像的相似性得分。在架构的最后结合了识别（分类）丢失和验证（相似）损失。
1. Rotation-invariant feature training
随机数据增强后的训练集为网络提供学习旋转不变特征。由于文章架构采用正/负对作为输入，随机旋转仅用于来自同一类别的图像的正对。在架构中有两个CNN通道，如图所示。一个CNN接受原始图像，同时，随机旋转图像，如果其他CNN通道接受正面（来自同类）。理想情况下，两个CNN网络将获得几乎相同的两个图像的特征。为此，文章添加了一个度量学习正则化项，由CNN学习这两个特征，这些特征强制训练样本有和没有随机旋转来共享相似的特征，从而实现旋转不变性
2. Joint decision making
为了充分利用识别和验证模型的组合，将联合决策机制引入到分类工作中。该机制旨在对这两种模型给出的概率关系进行编码。 考虑到整体结构，识别模型提取图像的特征以预测其类标签，其意味着该模型输出软最大概率Pi。 并且验证模型输出两个图像是否属于同一场景类的预测概率P. 首先，从训练集中随机选择与每个场景类相同数量的典型图像作为比较集。 然后，从测试集中对图像x和来自比较集的图像y进行采样，以生成输入对（x，y）。 整个网络将输出关于输入数据的两种概率。
![jdm](https://github.com/Fennyhhh/Fennyhhh.github.io/blob/master/paper_img/jdm.jpg)
每个形状代表一个场景类。 一个测试图像连同比较组中的图像通过整个网络馈送。 识别模型输出比较组中的图像的类概率Pi（j）（j = 1,2，...，K）。 同时，验证模型输出相似性测量值Pv（j），是test image与比较组中的每个单个图像之间的关系得分。 可以基于等式1获得一组P（x）（P1（x），P2（x），...，PK（x））。
## 总结与思考
该文章与与第一篇文章相同的是采用了两个CNN分支进行特征提取，该文章将相同类和不同类的图片进行通道融合，计算相似性，强调了类内相似性和类间差异性。联合决策机制是一个值得参考的方式，将训练概率和验证概率的相似性关系得分进行融合，可以在某种程度上解决训练集样本和验证集样本分布不一致的问题，可以有效防止过拟合。
